{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Title: Biomedical NER and SDoH Extraction from PubMed Abstracts with LLM Verification\n",
    "\n",
    "# --------------------------- 1. Setup and Imports ---------------------------\n",
    "!pip install transformers torch nltk seqeval spacy tqdm matplotlib sentence-transformers numpy==1.26.4\n",
    "!python -m spacy download en_core_web_sm\n",
    "\n",
    "import json\n",
    "import torch\n",
    "from transformers import AutoModelForTokenClassification, pipeline, AutoTokenizer\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# Ensure NLTK punkt data is downloaded\n",
    "nltk.download('punkt')"
   ],
   "id": "817be7e1d00cd52",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# --------------------------- 2. Load Data and Models ---------------------------\n",
    "\n",
    "# Update these paths if needed\n",
    "input_file = '../MS_SDoH_pubmed_abstracts_20241127.json'\n",
    "output_file = '../Processed_MS_SDoH_pubmed_abstracts_with_entities.json'\n",
    "\n",
    "with open(input_file, 'r', encoding='utf-8') as f:\n",
    "    articles = json.load(f)\n",
    "\n",
    "# Load BioBERT NER PrimeKGIntegration and tokenizer\n",
    "model_name = \"d4data/biomedical-ner-all\"\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    ner_model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "    print(\"BioBERT NER PrimeKGIntegration and tokenizer loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading PrimeKGIntegration '{model_name}': {e}\")\n",
    "    import sys\n",
    "    sys.exit()\n",
    "\n",
    "# Create NER pipeline\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "ner_pipeline = pipeline(\"ner\", model=ner_model, tokenizer=tokenizer, aggregation_strategy=\"simple\", device=device)\n",
    "print(f\"Using device: {'GPU' if device == 0 else 'CPU'}\")\n",
    "\n",
    "# Test the NER pipeline on a sample sentence\n",
    "test_sentence = \"The patient reported no recurrence of palpitations at follow-up 6 months after the ablation.\"\n",
    "print(\"\\nTesting NER pipeline with a sample sentence...\")\n",
    "try:\n",
    "    test_entities = ner_pipeline(test_sentence)\n",
    "    print(\"Test sentence entities:\")\n",
    "    print(json.dumps(test_entities, indent=4))\n",
    "except Exception as e:\n",
    "    print(f\"Error during NER pipeline test: {e}\")"
   ],
   "id": "5396a0ac46be0fe5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# --------------------------- 3. Perform NER on All Articles ---------------------------\n",
    "all_entities = []\n",
    "for article in tqdm(articles, desc=\"Processing abstracts\"):\n",
    "    abstract = article.get('abstract', '')\n",
    "    if abstract:\n",
    "        entities = ner_pipeline(abstract)\n",
    "        article['entities'] = entities\n",
    "        all_entities.extend(entities)\n",
    "    else:\n",
    "        article['entities'] = []\n",
    "\n",
    "# Count entity types\n",
    "entity_labels = [entity['entity_group'] for entity in all_entities]\n",
    "entity_counts = Counter(entity_labels)\n",
    "\n",
    "print(\"Entity Counts:\")\n",
    "for label, count in entity_counts.items():\n",
    "    print(f\"{label}: {count}\")\n",
    "\n",
    "# Optional: Plot entity counts\n",
    "if len(entity_counts) > 0:\n",
    "    labels, counts = zip(*entity_counts.items())\n",
    "    plt.bar(labels, counts)\n",
    "    plt.xlabel('Entity Type')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Entity Counts by Type')\n",
    "    plt.show()"
   ],
   "id": "987dcc919a9f1f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# --------------------------- 4. Define the Refined SDoH Ontology with Exact Matches ---------------------------\n",
    "sdoh_ontology = {\n",
    "    \"socioeconomic_factors\": {\n",
    "        \"poverty_low_income\": [\n",
    "            \"poverty\", \n",
    "            \"living in poverty\",\n",
    "            \"low income\",\n",
    "            \"low-income population\",\n",
    "            \"financial hardship\",\n",
    "            \"low socioeconomic status\"\n",
    "        ],\n",
    "        \"high_income_wealthy\": [\n",
    "            \"high income\",\n",
    "            \"high-income population\",\n",
    "            \"wealthy communities\",\n",
    "            \"high ses\"\n",
    "        ],\n",
    "        \"lower_education\": [\n",
    "            \"low education\",\n",
    "            \"low educational attainment\",\n",
    "            \"limited schooling\"\n",
    "        ],\n",
    "        \"higher_education\": [\n",
    "            \"high education\",\n",
    "            \"college-educated\",\n",
    "            \"high educational level\"\n",
    "        ],\n",
    "        \"lower_social_class\": [\n",
    "            \"lower social class\",\n",
    "            \"lower class\",\n",
    "            \"working class\"\n",
    "        ],\n",
    "        \"upper_social_class\": [\n",
    "            \"upper social class\",\n",
    "            \"middle class\",\n",
    "            \"upper class\"\n",
    "        ]\n",
    "    },\n",
    "    \"lifestyle_behavioral_factors\": {\n",
    "        \"nutrition_poor\": [\n",
    "            \"poor nutrition\",\n",
    "            \"unhealthy dietary habits\",\n",
    "            \"unhealthy diet\",\n",
    "            \"bad nutrition\"\n",
    "        ],\n",
    "        \"nutrition_high_fat\": [\n",
    "            \"high-fat diet\",\n",
    "            \"high fat diet\",\n",
    "            \"high fat dietary intake\"\n",
    "        ],\n",
    "        \"nutrition_balanced\": [\n",
    "            \"nutrition\",\n",
    "            \"good nutrition\",\n",
    "            \"balanced diet\",\n",
    "            \"nutrient-rich diet\",\n",
    "            \"healthy diet\",\n",
    "            \"balanced nutrition\"\n",
    "        ],\n",
    "        \"stress_high\": [\n",
    "            \"high stress\",\n",
    "            \"high stress levels\",\n",
    "            \"chronic stress\"\n",
    "        ],\n",
    "        \"stress_low\": [\n",
    "            \"low stress\",\n",
    "            \"low stress levels\",\n",
    "            \"reduced stress environment\"\n",
    "        ],\n",
    "        \"physical_activity_high\": [\n",
    "            \"physical activity\",\n",
    "            \"regular exercise\",\n",
    "            \"physically active lifestyle\"\n",
    "        ],\n",
    "        \"physical_activity_low\": [\n",
    "            \"sedentary lifestyle\",\n",
    "            \"sedentary behavior\"\n",
    "        ],\n",
    "        \"smoking_tobacco_use\": [\n",
    "            \"smoking\",\n",
    "            \"smoker\",\n",
    "            \"heavy smoking\",\n",
    "            \"current smoker\",\n",
    "            \"former smoker\",\n",
    "            \"tobacco use\"\n",
    "        ],\n",
    "        \"alcohol_use\": [\n",
    "            \"alcohol use\",\n",
    "            \"alcohol consumption\",\n",
    "            \"excessive alcohol consumption\",\n",
    "            \"moderate drinking\",\n",
    "            \"alcohol misuse\"\n",
    "        ],\n",
    "        \"substance_abuse\": [\n",
    "            \"substance abuse\",\n",
    "            \"illicit drug use\",\n",
    "            \"substance dependence\",\n",
    "            \"drug misuse\"\n",
    "        ],\n",
    "        \"general_unhealthy_lifestyle\": [\n",
    "            \"unhealthy lifestyle\",\n",
    "            \"unhealthy life\"\n",
    "        ],\n",
    "        \"general_healthy_lifestyle\": [\n",
    "            \"healthy lifestyle\",\n",
    "            \"health-promoting behaviors\"\n",
    "        ]\n",
    "    },\n",
    "    \"environmental_factors\": {\n",
    "        \"housing\": [\n",
    "            \"housing\",\n",
    "            \"poor housing conditions\",\n",
    "            \"overcrowded housing\",\n",
    "            \"stable housing\"\n",
    "        ],\n",
    "        \"neighborhood\": [\n",
    "            \"neighborhood\",\n",
    "            \"low-resource neighborhood\",\n",
    "            \"unsafe neighborhood\",\n",
    "            \"affluent neighborhood\"\n",
    "        ],\n",
    "        \"pollution_high\": [\n",
    "            \"pollution\",\n",
    "            \"high pollution exposure\",\n",
    "            \"environmental toxins\"\n",
    "        ],\n",
    "        \"urban_environment\": [\n",
    "            \"urban\",\n",
    "            \"urban environment\",\n",
    "            \"city dwelling\"\n",
    "        ],\n",
    "        \"rural_environment\": [\n",
    "            \"rural\",\n",
    "            \"rural setting\",\n",
    "            \"remote area\"\n",
    "        ],\n",
    "        \"high_latitude\": [\n",
    "            \"high latitude\",\n",
    "            \"high-latitude region\"\n",
    "        ],\n",
    "        \"low_latitude\": [\n",
    "            \"low latitude\",\n",
    "            \"low-latitude region\"\n",
    "        ],\n",
    "        \"transportation_limited\": [\n",
    "            \"transportation\",\n",
    "            \"limited transportation access\",\n",
    "            \"inadequate public transit\"\n",
    "        ],\n",
    "        \"food_insecurity\": [\n",
    "            \"food insecurity\",\n",
    "            \"food insecure\",\n",
    "            \"limited healthy food access\"\n",
    "        ],\n",
    "        \"general_environment\": [\n",
    "            \"environment\",\n",
    "            \"environmental factors\",\n",
    "            \"local environmental conditions\"\n",
    "        ]\n",
    "    },\n",
    "    \"cultural_social_factors\": {\n",
    "        \"demographic_identity_factors\": [\n",
    "            \"ethnicity\",\n",
    "            \"race\",\n",
    "            \"gender\",\n",
    "            \"ethnic minority group\",\n",
    "            \"racial minority\",\n",
    "            \"diverse racial background\",\n",
    "            \"female sex\",\n",
    "            \"male sex\",\n",
    "            \"gender minorities\"\n",
    "        ],\n",
    "        \"social_support_cultural_context\": [\n",
    "            \"social support\",\n",
    "            \"cultural beliefs\",\n",
    "            \"community\",\n",
    "            \"family\",\n",
    "            \"strong social support network\",\n",
    "            \"lack of social support\",\n",
    "            \"traditional cultural norms\",\n",
    "            \"tight-knit community\",\n",
    "            \"dysfunctional family environment\"\n",
    "        ]\n",
    "    },\n",
    "    \"health_system_related_factors\": {\n",
    "        \"access_to_care_limited\": [\n",
    "            \"no access to care\",\n",
    "            \"limited access to healthcare\",\n",
    "            \"barriers to care\"\n",
    "        ],\n",
    "        \"access_to_care_adequate\": [\n",
    "            \"access to care\",\n",
    "            \"adequate access to healthcare\",\n",
    "            \"improved healthcare availability\"\n",
    "        ],\n",
    "        \"health_disparities_inequality\": [\n",
    "            \"health disparities\",\n",
    "            \"inequality\",\n",
    "            \"health inequities\",\n",
    "            \"unequal healthcare access\",\n",
    "            \"healthcare inequality\"\n",
    "        ],\n",
    "        \"health_literacy_low\": [\n",
    "            \"low health literacy\",\n",
    "            \"limited health literacy\"\n",
    "        ],\n",
    "        \"health_literacy_high\": [\n",
    "            \"health literacy\",\n",
    "            \"high health literacy\",\n",
    "            \"understanding health information\"\n",
    "        ]\n",
    "    },\n",
    "    \"violence_safety_factors\": {\n",
    "        \"violence\": [\n",
    "            \"violence\",\n",
    "            \"exposure to violence\",\n",
    "            \"interpersonal violence\",\n",
    "            \"unsafe environment\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# --------------------------- 5. Prepare Embeddings for SDoH Ontology ---------------------------\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "flattened_ontology = {}\n",
    "for main_cat, subcats in sdoh_ontology.items():\n",
    "    for subcat, phrases in subcats.items():\n",
    "        category_name = f\"{main_cat}::{subcat}\"\n",
    "        flattened_ontology[category_name] = [p.lower() for p in phrases]\n",
    "\n",
    "ontology_embeddings = {}\n",
    "for cat_name, phrases in flattened_ontology.items():\n",
    "    cat_embeddings = embedding_model.encode(phrases, convert_to_tensor=True)\n",
    "    ontology_embeddings[cat_name] = cat_embeddings"
   ],
   "id": "5faf267ff30249da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "USE_LLM = True\n",
    "# --------------------------- LLM Initialization ---------------------------\n",
    "# Ensure you have the appropriate PrimeKGIntegration and permission\n",
    "if USE_LLM:\n",
    "    # Your Hugging Face access token\n",
    "    hf_token = \"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\"  # Replace with your actual token\n",
    "    \n",
    "    model_id = \"meta-llama/Llama-3.2-1B\"\n",
    "    \n",
    "    # Initialize the LLM pipeline with proper authentication and parameters\n",
    "    pipe = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model_id,\n",
    "        torch_dtype=torch.float16, # Use torch.bfloat16 if supported by your hardware\n",
    "        device_map=\"cpu\",\n",
    "        token=hf_token,           # Correct parameter for authentication\n",
    "        trust_remote_code=True    # Enable execution of remote code if necessary\n",
    "    )\n",
    "    \n",
    "    # Example usage\n",
    "    prompt = \"Once upon a time\"\n",
    "    response = pipe(prompt, max_length=50, truncation=True, temperature=0.4)\n",
    "    print(response)\n",
    "else:\n",
    "    print(f'Use LLM set to False, skipping LLM initialization.')"
   ],
   "id": "888ecf94792004d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import logging\n",
    "\n",
    "# --------------------------- Logger Initialization ---------------------------\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logger.info(f\"Beginning extraction and mapping of SDoH mentions from {len(articles)} articles.\")\n",
    "\n",
    "all_sdoh_mentions = []\n",
    "\n",
    "LOW_THRESHOLD = 0.5\n",
    "HIGH_THRESHOLD = 0.7\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "for idx, article in enumerate(tqdm(articles, desc=\"Processing Articles\")):\n",
    "    abstract = article.get('abstract', '')\n",
    "    sdoh_mentions = []\n",
    "\n",
    "    if abstract:\n",
    "        # Extract noun phrases using SpaCy\n",
    "        try:\n",
    "            doc = nlp(abstract)\n",
    "            noun_phrases = [chunk.text.strip() for chunk in doc.noun_chunks]\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during noun phrase extraction in Article {idx + 1}: {e}\")\n",
    "            noun_phrases = []\n",
    "\n",
    "        # Tokenize sentences using NLTK\n",
    "        try:\n",
    "            sentences = nltk.sent_tokenize(abstract)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during sentence tokenization in Article {idx + 1}: {e}\")\n",
    "            sentences = []\n",
    "\n",
    "        for phrase in noun_phrases:\n",
    "            phrase_text = phrase.lower()\n",
    "\n",
    "            # Encode the phrase to get its embedding\n",
    "            try:\n",
    "                phrase_embedding = embedding_model.encode(phrase_text, convert_to_tensor=True)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error encoding phrase '{phrase_text}' in Article {idx + 1}: {e}\")\n",
    "                continue  # Skip this phrase if encoding fails\n",
    "\n",
    "            best_cat = None\n",
    "            best_score = -1.0\n",
    "\n",
    "            # Compare phrase with each ontology category's embeddings\n",
    "            for cat_name, cat_embeddings in ontology_embeddings.items():\n",
    "                try:\n",
    "                    cosine_scores = util.cos_sim(phrase_embedding, cat_embeddings).squeeze(0)\n",
    "                    max_score = torch.max(cosine_scores).item()\n",
    "\n",
    "                    if max_score > best_score:\n",
    "                        best_score = max_score\n",
    "                        best_cat = cat_name\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error computing cosine similarity for category '{cat_name}' in Article {idx + 1}: {e}\")\n",
    "                    continue  # Skip this category if similarity computation fails\n",
    "\n",
    "            if best_cat is None:\n",
    "                logger.warning(f\"No suitable category found for phrase '{phrase}' in Article {idx + 1}. Skipping.\")\n",
    "                continue  # Skip if no category is found\n",
    "\n",
    "            if best_score < LOW_THRESHOLD:\n",
    "                continue  # Discard the phrase if below LOW_THRESHOLD\n",
    "            elif best_score > HIGH_THRESHOLD:\n",
    "                logger.info(f\"Phrase '{phrase}' assigned to category '{best_cat}' with similarity {best_score:.4f}.\")\n",
    "                sdoh_mentions.append({\n",
    "                    'phrase': phrase,\n",
    "                    'category': best_cat,\n",
    "                    'similarity': best_score\n",
    "                })\n",
    "                all_sdoh_mentions.append(best_cat)\n",
    "            else:\n",
    "                # Borderline case: Use LLM only if USE_LLM is True\n",
    "                if not USE_LLM:\n",
    "                    continue  # Discard to be conservative\n",
    "                else:\n",
    "                    # Find the sentence containing the phrase\n",
    "                    phrase_sent = next((s for s in sentences if phrase in s), abstract)\n",
    "\n",
    "                    # Create the prompt for the LLM\n",
    "                    prompt = (\n",
    "                        f\"Context: {phrase_sent}\\n\\n\"\n",
    "                        f\"Phrase: '{phrase}'\\n\"\n",
    "                        f\"Proposed Category: '{best_cat}'\\n\\n\"\n",
    "                        \"The phrase above is proposed to be classified under the given category of social determinants of health. \"\n",
    "                        \"Is it reasonable and semantically correct to classify this phrase under that category? \"\n",
    "                        \"Answer 'yes' if it is correct and 'no' if not.\"\n",
    "                    )\n",
    "\n",
    "                    # Generate response from LLM\n",
    "                    try:\n",
    "                        llm_response = pipe(\n",
    "                            prompt,\n",
    "                            max_new_tokens=5,\n",
    "                            temperature=0.4,\n",
    "                            top_k=50,\n",
    "                            top_p=0.95,\n",
    "                            return_full_text=False\n",
    "                        )[0]['generated_text'].strip().lower()\n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"Error during LLM generation for phrase '{phrase}' in Article {idx + 1}: {e}\")\n",
    "                        continue  # Skip LLM verification if generation fails\n",
    "\n",
    "                    # Interpret LLM response\n",
    "                    if \"yes\" in llm_response and \"no\" not in llm_response:\n",
    "                        logger.info(f\"LLM verified phrase '{phrase}' as correctly categorized under '{best_cat}'.\")\n",
    "                        sdoh_mentions.append({\n",
    "                            'phrase': phrase,\n",
    "                            'category': best_cat,\n",
    "                            'similarity': best_score,\n",
    "                            'verified_by_llm': True\n",
    "                        })\n",
    "                        all_sdoh_mentions.append(best_cat)\n",
    "                    else:\n",
    "                        continue  # Do not include the phrase if not verified by LLM\n",
    "    else:\n",
    "        logger.warning(f\"Article {idx + 1} does not contain an abstract. Skipping SDoH extraction.\")\n",
    "\n",
    "    # Assign the extracted SDoH mentions to the article\n",
    "    article['sdoh_mentions'] = sdoh_mentions\n",
    "\n",
    "# --------------------------- Counting SDoH Mentions ---------------------------\n",
    "logger.info(\"Counting all SDoH mentions across processed articles.\")\n",
    "sdoh_counts = Counter(all_sdoh_mentions)\n",
    "\n",
    "logger.info(\"\\nSDoH Mentions Counts:\")\n",
    "for sdoh, count in sdoh_counts.items():\n",
    "    logger.info(f\"{sdoh}: {count}\")\n",
    "\n",
    "# --------------------------- Plotting Top SDoH Mentions ---------------------------\n",
    "if sdoh_counts:\n",
    "    logger.info(\"Plotting top 10 SDoH mentions.\")\n",
    "    try:\n",
    "        top_sdoh = sdoh_counts.most_common(10)\n",
    "        sdoh_labels, sdoh_counts_values = zip(*top_sdoh)\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.bar(sdoh_labels, sdoh_counts_values, color='skyblue')\n",
    "        plt.xlabel('SDoH Category')\n",
    "        plt.ylabel('Count')\n",
    "        plt.title('Top 10 SDoH Mentions')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        logger.info(\"Plot displayed successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during plotting SDoH mentions: {e}\")\n",
    "else:\n",
    "    logger.info(\"No SDoH mentions found to plot.\")\n"
   ],
   "id": "f7020590aa471b5f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# --------------------------- 7. Save Processed Data ---------------------------\n",
    "import json\n",
    "\n",
    "def ensure_serializable(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: ensure_serializable(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [ensure_serializable(v) for v in obj]\n",
    "    elif isinstance(obj, float):\n",
    "        # Convert any float (including np.float32/64) to Python float\n",
    "        return float(obj)\n",
    "    elif hasattr(obj, 'item') and callable(obj.item):\n",
    "        # If it's a numpy scalar or torch scalar, convert it to Python float\n",
    "        return float(obj.item())\n",
    "    else:\n",
    "        # For other types, just return as is. If they cause issues,\n",
    "        # handle them similarly.\n",
    "        return obj\n",
    "\n",
    "# Apply the function to your articles data before dumping\n",
    "articles = ensure_serializable(articles)\n",
    "\n",
    "# Now save to JSON\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(articles, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Processed data with mapped entities saved to {output_file}\")"
   ],
   "id": "2ced016da3e574d8",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
